version: "3"

services:
  postgresql:
    image: kafka-sandbox-db
    container_name: kafka-sandbox-db
    build:
      context: ./resources/db
      dockerfile: Dockerfile
    restart: unless-stopped
    ports:
      - 5432:5432
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -d kafka-sandbox -U postgress"]
      interval: 3s
      timeout: 5s
      retries: 6
    volumes:
      - kafka-sandbox-db-data:/var/lib/postgresql/data
    networks:
      - broker-kafka

  zookeeper:
    # image: confluentinc/cp-zookeeper:7.2.6
    image: confluentinc/cp-zookeeper:6.2.0
    container_name: zookeeper
    networks:
      - broker-kafka
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_LOG4J_ROOT_LOGLEVEL: WARN
      ZOOKEEPER_TOOLS_LOG4J_LOGLEVEL: ERROR
    healthcheck:
      test: echo stat | nc localhost 2181 || exit 1
      interval: 10s
      retries: 5
      start_period: 5s
    volumes:
      - zookeeper-secrets:/etc/zookeeper/secrets:Z
      - zookeeper-data:/var/lib/zookeeper/data:Z
      - zookeeper-log:/var/lib/zookeeper/log:Z

  kafka:
    image: confluentinc/cp-kafka:6.2.0
    container_name: kafka
    networks:
      - broker-kafka
    depends_on:
      zookeeper:
        condition: service_healthy
        required: true
    ports:
      - "9092:9092"
      - "9101:9101"
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server kafka:29092 --list"]
      interval: 10s
      retries: 10
      timeout: 30s
    volumes:
      - kafka-data:/var/lib/kafka/data:Z
      - kafka-secrets:/etc/kafka/secrets:Z
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ADVERTISED_HOST_NAME: kafka:9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      # KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      # KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      # KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      # KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      # KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      # KAFKA_JMX_PORT: 9101
      # KAFKA_JMX_HOSTNAME: localhost
      # KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka:9092
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_ENABLE: true
      CONFLUENT_SUPPORT_CUSTOMER_ID: anonymous
      KAFKA_LOG4J_ROOT_LOGLEVEL: ERROR
      KAFKA_TOOLS_LOG4J_LOGLEVEL: ERROR

    # image: confluentinc/cp-server:7.2.6
    # container_name: kafka
    # depends_on:
    #   zookeeper:
    #     condition: service_healthy
    #     required: true
    # ports:
    #   - 9092:9092
    #   - 9101:9101
    # environment:
    #   KAFKA_BROKER_ID: 1
    #   KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    #   KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
    #   KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
    #   KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    #   KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    #   KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
    #   KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
    #   KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
    #   KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    #   KAFKA_JMX_PORT: 9101
    #   KAFKA_JMX_HOSTNAME: localhost
    #   KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081
    #   CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka:9092
    #   CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
    #   CONFLUENT_METRICS_ENABLE: true
    #   CONFLUENT_SUPPORT_CUSTOMER_ID: anonymous
    #   KAFKA_LOG4J_ROOT_LOGLEVEL: ERROR
    #   KAFKA_TOOLS_LOG4J_LOGLEVEL: ERROR
    # healthcheck:
    #   test: nc -z localhost 9092
    #   interval: 10s
    #   retries: 10
    #   start_period: 30s
    # volumes:
    #   - kafka-data:/var/lib/kafka/data:Z
    #   - kafka-secrets:/etc/kafka/secrets:Z
    # networks:
    #   - broker-kafka

  kafdrop:
    image: obsidiandynamics/kafdrop:3.27.0
    networks:
      - broker-kafka
    depends_on:
      kafka:
        condition: service_healthy
        required: true
      zookeeper:
        condition: service_healthy
        required: true
    ports:
      - 19000:9000
    environment:
      KAFKA_BROKERCONNECT: kafka:29092

  # schema-registry:
  #   image: confluentinc/cp-schema-registry:7.2.1
  #   container_name: schema-registry
  #   depends_on:
  #     kafka:
  #       condition: service_healthy
  #       required: true
  #   ports:
  #     - 8081:8081
  #   environment:
  #     SCHEMA_REGISTRY_HOST_NAME: schema-registry
  #     SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka:9092
  #     SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
  #     SCHEMA_REGISTRY_LOG4J_ROOT_LOGLEVEL: ERROR
  #     SCHEMA_REGISTRY_TOOLS_LOG4J_LOGLEVEL: ERROR
  #   healthcheck:
  #     test: curl --output /dev/null --user superUser:superUser --fail --silent --insecure http://localhost:8081/subjects || exit 1
  #     interval: 10s
  #     retries: 10
  #     start_period: 10s
  #   volumes:
  #     - schema-registry-secrets:/etc/schema-registry/secrets
  #   networks:
  #     - broker-kafka

  # schema-registry-ui:
  #   image: landoop/schema-registry-ui
  #   container_name: schema-registry-ui
  #   depends_on:
  #     schema-registry:
  #       condition: service_healthy
  #       required: true
  #   ports:
  #     - 8000:8000
  #   environment:
  #     SCHEMAREGISTRY_URL: http://schema-registry:8081
  #     PROXY: true
  #   healthcheck:
  #     test: wget --quiet --tries=1 --spider http://localhost:8000 || exit 1
  #     interval: 10s
  #     retries: 3
  #     start_period: 10s
  #   networks:
  #     - broker-kafka

  # control-center:
  #   image: confluentinc/cp-enterprise-control-center:7.2.1
  #   container_name: control-center
  #   depends_on:
  #     kafka:
  #       condition: service_healthy
  #     schema-registry:
  #       condition: service_healthy
  #   ports:
  #     - 9021:9021
  #   environment:
  #     CONTROL_CENTER_BOOTSTRAP_SERVERS: kafka:9092
  #     CONTROL_CENTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
  #     CONTROL_CENTER_REPLICATION_FACTOR: 1
  #     CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
  #     CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
  #     CONTROL_CENTER_LOG4J_ROOT_LOGLEVEL: WARN
  #     CONTROL_CENTER_TOOLS_LOG4J_LOGLEVEL: ERROR
  #     CONFLUENT_METRICS_TOPIC_REPLICATION: 1
  #     PORT: 9021
  #   healthcheck:
  #     test: curl --output /dev/null --fail --silent http://control-center:9021 || exit 1
  #     interval: 10s
  #     retries: 3
  #     start_period: 30s
  #   networks:
  #     - broker-kafka

  # rest-proxy:
  #   image: confluentinc/cp-kafka-rest:7.2.1
  #   container_name: rest-proxy
  #   depends_on:
  #     kafka:
  #       condition: service_healthy
  #     schema-registry:
  #       condition: service_healthy
  #       required: true
  #   ports:
  #     - 8082:8082
  #   environment:
  #     KAFKA_REST_HOST_NAME: rest-proxy
  #     KAFKA_REST_BOOTSTRAP_SERVERS: kafka:9092
  #     KAFKA_REST_LISTENERS: http://0.0.0.0:8082
  #     KAFKA_REST_SCHEMA_REGISTRY_URL: http://schema-registry:8081
  #     KAFKA_REST_LOG4J_ROOT_LOGLEVEL: WARN
  #     KAFKA_REST_TOOLS_LOG4J_LOGLEVEL: ERROR
  #   healthcheck:
  #     test: curl --output /dev/null --silent --head --fail http://rest-proxy:8082
  #     interval: 10s
  #     retries: 3
  #     start_period: 30s
  #   networks:
  #     - broker-kafka

  publisher:
    container_name: publisher
    build:
      context: ./publisher
      dockerfile: Dockerfile
    environment:
      - KAFKA_TOPIC_NAME=topic_test
      - KAFKA_SERVER=kafka
      - KAFKA_PORT=29092
    ports:
      - 8000:8000
    restart: always
    depends_on:
      - zookeeper
      - kafka
    networks:
      - broker-kafka

  consumer1:
    container_name: consumer1
    build:
      context: ./consumer1
      dockerfile: Dockerfile
    environment:
      - KAFKA_TOPIC_NAME=topic_test
      - KAFKA_SERVER=kafka
      - KAFKA_PORT=29092
    ports:
      - 8001:8001
    restart: always
    depends_on:
      - zookeeper
      - kafka
      - publisher
    networks:
      - broker-kafka

  consumer2:
    container_name: consumer2
    build:
      context: ./consumer2
      dockerfile: Dockerfile.dev
    ports:
      - 8002:8002
    tty: true
    environment:
      - NODE_ENV=development
      - PORT=8002
      - POSTGRES_DB=kafka-sandbox
      - POSTGRES_USER=postgress
      - POSTGRES_PASSWORD=postgress
      - POSTGRES_PORT=5432
      - POSTGRES_HOST=kafka-sandbox-db
      - DATABASE_LOGGING=true
      - KAFKA_TOPIC_NAME=topic_test
      - KAFKA_SERVER=kafka
      - KAFKA_PORT=29092
    restart: always
    volumes:
      - ./consumer2:/app
    depends_on:
      postgresql:
        condition: service_healthy
      zookeeper:
        condition: service_healthy
      kafka:
        condition: service_healthy
      publisher:
        condition: service_healthy
    networks:
      - broker-kafka

  consumer3:
    container_name: consumer3
    build:
      context: ./consumer3
    ports:
      - 8003:8003
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8003/healthcheck"]
      interval: 10s
      timeout: 5s
      retries: 3
    tty: true
    environment:
      - NODE_ENV=development
      - PORT=8003
      - KAFKA_TOPIC_NAME=topic_test
      - KAFKA_SERVER=kafka
      - KAFKA_PORT=29092
    restart: always
    depends_on:
      zookeeper:
        condition: service_healthy
      kafka:
        condition: service_healthy
      publisher:
        condition: service_healthy
    networks:
      - broker-kafka

volumes:
  zookeeper-secrets:
    name: zookeeper-secrets
  zookeeper-data:
    name: zookeeper-data
  zookeeper-log:
    name: zookeeper-log
  kafka-data:
    name: kafka-data
  kafka-secrets:
    name: kafka-secrets
  schema-registry-secrets:
    name: schema-registry-secrets
  kafka-sandbox-db-data:
    name: kafka-sandbox-db-data

networks:
  broker-kafka:
    driver: bridge
